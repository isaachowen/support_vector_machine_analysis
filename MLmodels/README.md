# MLmodels

# Isaac was here

# Things you can try
# On PIE, you can try a hilbert space

# Try different kernels: Linear, Polynomial, RBF, and Sigmoid, Gaussian

# Play with svm hyperparameters
#   slack variables--> C, The C parameter trades off correct classification of training examples against maximization of the decision functionâ€™s margin. For larger values of C, a smaller margin will be                               accepted if the decision function is better at classifying all training points correctly. 

#Other SVM parameters: 
#   cache_size      ?
#   class_weight    ?
#   coef0           ?
#   decision_function_shape     ?
#   degree          ?
#   gamma           ?
#   kernel          rbf? linear?
#   max_iter        ?
#   probability     ? t/f
#   random_state    ?
#   shrinking       ?
#   tol             ?
#   verbose turn this on

# doing a PCA (for Cho and Iyer)

# trying different methods for making class boundaries: 1 to all others or 1 to 1 for each pair of classes

# {'C': 0.1,
#  'break_ties': False,
#  'cache_size': 200,
#  'class_weight': None,
#  'coef0': 0.0,
#  'decision_function_shape': 'ovr',
#  'degree': 3,
#  'gamma': 0.5,
#  'kernel': 'rbf',
#  'max_iter': -1,
#  'probability': False,
#  'random_state': None,
#  'shrinking': True,
#  'tol': 0.001,
#  'verbose': False}



# How does sklearn svm deal with multiple classes?